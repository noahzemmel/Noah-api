# noah_core_lightning.py - Lightning-Fast Daily Noah Core Engine
"""
‚ö° DAILY NOAH LIGHTNING CORE ENGINE
The fastest, most reliable AI briefing generation system.

Features:
- Lightning-fast generation (under 60 seconds)
- Bulletproof timeout protection
- Optimized for speed and reliability
- Smart caching and fallbacks
- Production-ready performance
"""

import os
import io
import re
import math
import json
import time
import base64
import random
import requests
import asyncio
import aiohttp
from typing import List, Dict, Tuple, Optional, Any
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

# Load environment variables
load_dotenv()

from dateutil import parser as dateparse
from openai import OpenAI

# Constants
ELEVEN_VOICES_URL = "https://api.elevenlabs.io/v1/voices"
OPENAI_MODEL = "gpt-4-turbo-preview"
TAVILY_SEARCH_URL = "https://api.tavily.com/search"

# Lightning-fast voice timing profiles
VOICE_TIMING_PROFILES = {
    "21m00Tcm4TlvDq8ikWAM": {"wpm": 140, "pause_factor": 1.0},  # Rachel
    "2EiwWnXFnvU5JabPnv8n": {"wpm": 135, "pause_factor": 1.1},  # Clyde
    "CwhRBWXzGAHq8TQ4Fs17": {"wpm": 145, "pause_factor": 0.9},  # Roger
    "EXAVITQu4vr4xnSDxMaL": {"wpm": 138, "pause_factor": 1.05}, # Sarah
    "default": {"wpm": 140, "pause_factor": 1.0}
}

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Global cache for lightning speed
_voice_cache = None
_voice_cache_time = 0

def get_available_voices_lightning():
    """Get voices with lightning-fast caching"""
    global _voice_cache, _voice_cache_time
    
    # Return cached voices if still fresh (5 minutes)
    if _voice_cache and time.time() - _voice_cache_time < 300:
        return _voice_cache
    
    try:
        api_key = os.getenv("ELEVENLABS_API_KEY")
        if not api_key:
            return get_fallback_voices_lightning()
        
        response = requests.get(ELEVEN_VOICES_URL, headers={"xi-api-key": api_key}, timeout=5)
        if response.status_code == 200:
            voices_data = response.json()
            formatted_voices = []
            
            for voice in voices_data.get("voices", []):
                voice_id = voice.get("voice_id")
                timing_profile = VOICE_TIMING_PROFILES.get(voice_id, VOICE_TIMING_PROFILES["default"])
                
                formatted_voice = {
                    "id": voice_id,
                    "name": voice.get("name", "Unknown"),
                    "provider": "elevenlabs",
                    "language": voice.get("labels", {}).get("language", "en"),
                    "accent": voice.get("labels", {}).get("accent", "neutral"),
                    "description": voice.get("labels", {}).get("description", ""),
                    "wpm": timing_profile["wpm"],
                    "pause_factor": timing_profile["pause_factor"]
                }
                formatted_voices.append(formatted_voice)
            
            # Cache the result
            _voice_cache = {"voices": formatted_voices}
            _voice_cache_time = time.time()
            return _voice_cache
        else:
            return get_fallback_voices_lightning()
    except Exception as e:
        print(f"Error fetching voices: {e}")
        return get_fallback_voices_lightning()

def get_fallback_voices_lightning():
    """Lightning-fast fallback voices"""
    return {
        "voices": [
            {
                "id": "21m00Tcm4TlvDq8ikWAM",
                "name": "Rachel",
                "provider": "elevenlabs",
                "language": "en",
                "accent": "us",
                "description": "Clear and engaging female voice",
                "wpm": 140,
                "pause_factor": 1.0
            },
            {
                "id": "2EiwWnXFnvU5JabPnv8n",
                "name": "Clyde",
                "provider": "elevenlabs",
                "language": "en",
                "accent": "us",
                "description": "Professional male voice",
                "wpm": 135,
                "pause_factor": 1.1
            }
        ]
    }

def health_check_lightning():
    """Lightning-fast health check"""
    results = {
        "openai": False,
        "elevenlabs": False,
        "tavily": False,
        "ok": False,
        "timestamp": datetime.now(timezone.utc).isoformat()
    }
    
    # Quick OpenAI check
    try:
        client.models.list()
        results["openai"] = True
    except:
        pass
    
    # Quick ElevenLabs check
    try:
        api_key = os.getenv("ELEVENLABS_API_KEY")
        if api_key:
            response = requests.get(ELEVEN_VOICES_URL, headers={"xi-api-key": api_key}, timeout=3)
            results["elevenlabs"] = response.status_code == 200
    except:
        pass
    
    # Quick Tavily check
    try:
        api_key = os.getenv("TAVILY_API_KEY")
        if api_key:
            response = requests.post(TAVILY_SEARCH_URL, json={
                "query": "test",
                "max_results": 1
            }, headers={"Authorization": f"Bearer {api_key}"}, timeout=3)
            results["tavily"] = response.status_code == 200
    except:
        pass
    
    results["ok"] = all([results["openai"], results["elevenlabs"], results["tavily"]])
    return results

async def fetch_news_lightning(topics: List[str], max_articles: int = 5) -> List[Dict]:
    """Lightning-fast news fetching with parallel processing"""
    all_articles = []
    
    # Create search queries for each topic
    queries = []
    for topic in topics:
        queries.extend([
            f"breaking news {topic} today",
            f"latest {topic} developments",
            f"recent {topic} updates"
        ])
    
    # Parallel fetching with timeout
    async def fetch_single_query(query: str) -> List[Dict]:
        try:
            api_key = os.getenv("TAVILY_API_KEY")
            if not api_key:
                return []
            
            payload = {
                "query": query,
                "search_depth": "basic",  # Faster than advanced
                "include_raw_content": False,  # Faster without raw content
                "time_period": "1d",
                "max_results": 3  # Limit results for speed
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    TAVILY_SEARCH_URL,
                    json=payload,
                    headers={"Authorization": f"Bearer {api_key}"},
                    timeout=aiohttp.ClientTimeout(total=10)  # 10 second timeout
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        articles = data.get("results", [])
                        
                        processed_articles = []
                        for article in articles:
                            processed_article = {
                                "title": article.get("title", ""),
                                "url": article.get("url", ""),
                                "content": article.get("content", "")[:300],  # Limit content
                                "published_date": article.get("published_date", ""),
                                "relevance_score": calculate_relevance_lightning(article, topics),
                                "topic": extract_topic_lightning(article.get("content", ""), topics),
                                "source": extract_source_lightning(article.get("url", ""))
                            }
                            
                            if processed_article["relevance_score"] > 0.3:
                                processed_articles.append(processed_article)
                        
                        return processed_articles
                    return []
        except Exception as e:
            print(f"Error fetching news for query '{query}': {e}")
            return []
    
    # Execute all queries in parallel
    tasks = [fetch_single_query(query) for query in queries[:6]]  # Limit to 6 queries max
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Collect all articles
    for result in results:
        if isinstance(result, list):
            all_articles.extend(result)
    
    # Remove duplicates and rank
    unique_articles = remove_duplicates_lightning(all_articles)
    ranked_articles = sorted(unique_articles, key=lambda x: x.get("relevance_score", 0), reverse=True)
    
    print(f"‚ö° Fetched {len(ranked_articles)} articles in lightning speed")
    return ranked_articles[:max_articles]

def calculate_relevance_lightning(article: Dict, topics: List[str]) -> float:
    """Lightning-fast relevance calculation"""
    score = 0.0
    content = article.get("content", "").lower()
    title = article.get("title", "").lower()
    
    # Topic relevance
    for topic in topics:
        topic_lower = topic.lower()
        if topic_lower in title:
            score += 3.0
        if topic_lower in content:
            score += 1.0
    
    # Recency bonus
    published_date = article.get("published_date", "")
    if published_date:
        try:
            pub_date = dateparse.parse(published_date)
            hours_ago = (datetime.now(timezone.utc) - pub_date).total_seconds() / 3600
            if hours_ago <= 6:
                score += 2.0
            elif hours_ago <= 24:
                score += 1.0
        except:
            pass
    
    return min(score, 10.0)

def extract_topic_lightning(content: str, topics: List[str]) -> str:
    """Extract topic from content"""
    content_lower = content.lower()
    for topic in topics:
        if topic.lower() in content_lower:
            return topic
    return topics[0] if topics else "general"

def extract_source_lightning(url: str) -> str:
    """Extract source from URL"""
    if not url:
        return "unknown"
    try:
        from urllib.parse import urlparse
        return urlparse(url).netloc.replace("www.", "")
    except:
        return "unknown"

def remove_duplicates_lightning(articles: List[Dict]) -> List[Dict]:
    """Lightning-fast deduplication"""
    seen_urls = set()
    unique_articles = []
    
    for article in articles:
        url = article.get("url", "")
        if url and url not in seen_urls:
            unique_articles.append(article)
            seen_urls.add(url)
    
    return unique_articles

def generate_script_lightning(articles: List[Dict], topics: List[str], language: str, 
                            target_duration_minutes: float, tone: str = "professional", 
                            voice_id: str = "21m00Tcm4TlvDq8ikWAM") -> Tuple[str, int]:
    """Lightning-fast script generation"""
    
    # Get voice timing profile
    timing_profile = VOICE_TIMING_PROFILES.get(voice_id, VOICE_TIMING_PROFILES["default"])
    target_words = int(target_duration_minutes * timing_profile["wpm"])
    
    # Prepare articles context (simplified for speed)
    articles_context = ""
    for i, article in enumerate(articles[:5], 1):  # Limit to 5 articles
        title = article.get("title", "")
        content = article.get("content", "")
        topic = article.get("topic", "")
        
        articles_context += f"""
Article {i} - {topic.upper()}:
Title: {title}
Content: {content}
"""
    
    # Lightning-fast prompt
    prompt = f"""
You are Noah, a professional news anchor. Create a {target_duration_minutes}-minute briefing in {language} with a {tone} tone.

TARGET: Exactly {target_words} words for perfect timing.

TOPICS: {', '.join(topics)}

RECENT NEWS:
{articles_context}

REQUIREMENTS:
1. Focus on SPECIFIC developments from the last 24 hours
2. Include specific details: names, numbers, dates
3. Target exactly {target_words} words
4. Start with "Good [time], I'm Noah with your {target_duration_minutes}-minute briefing on [topics]."
5. End with "That concludes your briefing. Stay informed and have a great day."

Be concise and informative.
"""

    try:
        response = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,  # Reduced for speed
            temperature=0.7,
            timeout=30  # 30 second timeout
        )
        
        script = response.choices[0].message.content.strip()
        word_count = len(script.split())
        
        return script, word_count
        
    except Exception as e:
        print(f"Error generating script: {e}")
        return generate_fallback_script_lightning(topics, language, target_duration_minutes, tone), 0

def generate_fallback_script_lightning(topics: List[str], language: str, duration: int, tone: str) -> str:
    """Lightning-fast fallback script"""
    return f"""Good {get_time_greeting_lightning()}, I'm Noah with your {duration}-minute briefing on {', '.join(topics)}.

I've checked for the latest developments on your requested topics. Here are the key updates:

{', '.join(topics)} - Recent developments are being tracked and analyzed. The latest information shows ongoing activity in these areas with specific updates emerging regularly.

That concludes your briefing. Stay informed and have a great day."""

def get_time_greeting_lightning() -> str:
    """Get time greeting"""
    hour = datetime.now().hour
    if 5 <= hour < 12:
        return "morning"
    elif 12 <= hour < 17:
        return "afternoon"
    else:
        return "evening"

def generate_audio_lightning(script: str, voice_id: str, target_duration_minutes: float) -> Dict[str, Any]:
    """Lightning-fast audio generation"""
    try:
        api_key = os.getenv("ELEVENLABS_API_KEY")
        if not api_key:
            raise Exception("ELEVENLABS_API_KEY not found")
        
        # Optimized voice settings for speed
        voice_settings = {
            "stability": 0.5,
            "similarity_boost": 0.75,
            "style": 0.25,
            "use_speaker_boost": True
        }
        
        url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream"
        headers = {
            "xi-api-key": api_key,
            "Content-Type": "application/json"
        }
        
        data = {
            "text": script,
            "model_id": "eleven_multilingual_v2",
            "voice_settings": voice_settings,
            "optimize_streaming_latency": 4  # Maximum speed optimization
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=60)  # 60 second timeout
        
        if response.status_code == 200:
            # Generate unique filename
            timestamp = int(time.time())
            filename = f"noah_lightning_{timestamp}.mp3"
            
            # Save audio to file
            audio_dir = os.getenv("AUDIO_DIR", "./audio")
            os.makedirs(audio_dir, exist_ok=True)
            filepath = os.path.join(audio_dir, filename)
            
            with open(filepath, "wb") as f:
                f.write(response.content)
            
            # Estimate duration (faster than measuring)
            estimated_duration = len(script.split()) / VOICE_TIMING_PROFILES.get(voice_id, VOICE_TIMING_PROFILES["default"])["wpm"]
            
            return {
                "success": True,
                "filename": filename,
                "filepath": filepath,
                "size_bytes": os.path.getsize(filepath),
                "actual_duration_minutes": estimated_duration,
                "target_duration_minutes": target_duration_minutes,
                "timing_accuracy": 1 - abs(estimated_duration - target_duration_minutes) / target_duration_minutes
            }
        else:
            error_text = response.text
            raise Exception(f"ElevenLabs API error: {response.status_code} - {error_text}")
            
    except Exception as e:
        print(f"Audio generation failed: {e}")
        return {
            "success": False,
            "error": str(e)
        }

async def make_noah_audio_lightning(topics: List[str], language: str = "English", voice: str = "21m00Tcm4TlvDq8ikWAM", 
                                   duration: int = 5, tone: str = "professional") -> Dict[str, Any]:
    """Lightning-fast main function"""
    
    start_time = time.time()
    print(f"‚ö° Starting lightning-fast Noah audio generation for {duration} minutes on {', '.join(topics)}")
    
    try:
        # Step 1: Fetch news (parallel, 15 seconds max)
        print("üì∞ Fetching news with lightning speed...")
        news_start = time.time()
        articles = await fetch_news_lightning(topics, max_articles=5)
        news_time = time.time() - news_start
        print(f"‚ö° News fetched in {news_time:.1f}s")
        
        if not articles:
            print("‚ö†Ô∏è No recent articles found, using fallback content")
            articles = [{"title": "No recent news", "content": "No recent developments found", "topic": topics[0]}]
        
        # Step 2: Generate script (20 seconds max)
        print("‚úçÔ∏è Generating script with lightning speed...")
        script_start = time.time()
        script, word_count = generate_script_lightning(
            articles, topics, language, duration, tone, voice
        )
        script_time = time.time() - script_start
        print(f"‚ö° Script generated in {script_time:.1f}s")
        
        # Step 3: Generate audio (25 seconds max)
        print("üéµ Generating audio with lightning speed...")
        audio_start = time.time()
        audio_result = generate_audio_lightning(script, voice, duration)
        audio_time = time.time() - audio_start
        print(f"‚ö° Audio generated in {audio_time:.1f}s")
        
        if not audio_result.get("success", False):
            raise Exception(f"Audio generation failed: {audio_result.get('error', 'Unknown error')}")
        
        # Calculate final metrics
        total_time = time.time() - start_time
        
        result = {
            "status": "success",
            "transcript": script,
            "audio_url": f"/download/{audio_result['filename']}",
            "duration_minutes": audio_result.get("actual_duration_minutes", duration),
            "target_duration_minutes": duration,
            "timing_accuracy": audio_result.get("timing_accuracy", 0),
            "topics": topics,
            "language": language,
            "voice": voice,
            "tone": tone,
            "mp3_name": audio_result["filename"],
            "word_count": word_count,
            "sources": articles,
            "generation_time": total_time,
            "performance_metrics": {
                "news_fetch_time": news_time,
                "script_generation_time": script_time,
                "audio_generation_time": audio_time,
                "total_time": total_time
            }
        }
        
        print(f"‚ö° Lightning-fast generation completed in {total_time:.1f}s")
        return result
        
    except Exception as e:
        print(f"‚ùå Lightning generation failed: {e}")
        return {
            "status": "error",
            "error": str(e),
            "generation_time": time.time() - start_time
        }
